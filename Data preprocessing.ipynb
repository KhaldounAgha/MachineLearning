{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Preprocessing of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat is Data Scaling?\\nData scaling is the process of changing the range of values in a dataset to a common scale, \\nwithout distorting the differences in the ranges or losing information. \\nIt's typically applied to numerical features in a dataset.\\n\\nWhy Scale Data?\\nUniform Feature Importance: Scaling ensures that all features contribute equally to the analysis or model training process.\\nImproved Algorithm Performance: Many machine learning algorithms perform better or converge faster when features are on a similar scale.\\nPrevent Dominance: It prevents features with larger numeric ranges from dominating those with smaller ranges.\\nNumerical Stability: Some algorithms are sensitive to the scale of input features and may become numerically unstable without scaling.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### \n",
    "\"\"\"\n",
    "What is Data Scaling?\n",
    "Data scaling is the process of changing the range of values in a dataset to a common scale, \n",
    "without distorting the differences in the ranges or losing information. \n",
    "It's typically applied to numerical features in a dataset.\n",
    "\n",
    "Why Scale Data?\n",
    "Uniform Feature Importance: Scaling ensures that all features contribute equally to the analysis or model training process.\n",
    "Improved Algorithm Performance: Many machine learning algorithms perform better or converge faster when features are on a similar scale.\n",
    "Prevent Dominance: It prevents features with larger numeric ranges from dominating those with smaller ranges.\n",
    "Numerical Stability: Some algorithms are sensitive to the scale of input features and may become numerically unstable without scaling.\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of data for machine learning (preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  3.  -6.4]\n",
      " [ 0.   3.  -1.3  4.1]\n",
      " [ 1.   2.3 -2.9  4.3]\n",
      " [ 2.   2.8 -2.3  4.5]\n",
      " [-1.   3.3 -1.9  4.2]\n",
      " [ 1.   0.   0.   5. ]]\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([[3, -1.5, 3, -6.4], [0, 3, -1.3, 4.1], [1, 2.3, -2.9, 4.3], [2, 2.8, -2.3, 4.5], [-1, 3.3, -1.9, 4.2], [1, 0, 0, 5]]) \n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = [ 1.          1.65       -0.9         2.61666667]\n",
      "Std deviation = [1.29099445 1.77646653 1.96383978 4.04286065]\n"
     ]
    }
   ],
   "source": [
    "print (\"Mean =\", input_data.mean(axis=0)) \n",
    "print (\"Std deviation =\", input_data.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Standardization (Z-score Normalization)\\nTransforms data to have a mean of 0 and a standard deviation of 1.\\nFormula: X_scaled = (X - μ) / σ\\nWhere μ is the mean and σ is the standard deviation.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\"\"\"\n",
    "1. Standardization (Z-score Normalization)\n",
    "Transforms data to have a mean of 0 and a standard deviation of 1.\n",
    "Formula: X_scaled = (X - μ) / σ\n",
    "Where μ is the mean and σ is the standard deviation.\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.54919334 -1.77318286  1.98590539 -2.23026897]\n",
      " [-0.77459667  0.75993551 -0.2036826   0.36690192]\n",
      " [ 0.          0.36589488 -1.01841302  0.41637184]\n",
      " [ 0.77459667  0.64735247 -0.71288911  0.46584176]\n",
      " [-1.54919334  0.92881007 -0.50920651  0.39163688]\n",
      " [ 0.         -0.92881007  0.45828586  0.58951657]]\n"
     ]
    }
   ],
   "source": [
    "data_standardized = preprocessing.scale(input_data) \n",
    "print(data_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  [0. 0. 0. 0.]\n",
      "Std deviation =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Mean = ', f'{data_standardized.mean(axis=0).round(2)}')\n",
    "print(\"Std deviation = \", data_standardized.std(axis=0).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2. Min-max Normalization\\nTransforms data to have a range between 0 and 1.\\nFormula: X_normalized = (X - min(X)) / (max(X) - min(X))\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\"\"\"\n",
    "2. Min-max Normalization\n",
    "Transforms data to have a range between 0 and 1.\n",
    "Formula: X_normalized = (X - min(X)) / (max(X) - min(X))\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         1.         0.        ]\n",
      " [0.25       0.9375     0.27118644 0.92105263]\n",
      " [0.5        0.79166667 0.         0.93859649]\n",
      " [0.75       0.89583333 0.10169492 0.95614035]\n",
      " [0.         1.         0.16949153 0.92982456]\n",
      " [0.5        0.3125     0.49152542 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_normalized = preprocessing.minmax_scale(input_data) \n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min =  [0. 0. 0. 0.]\n",
      "Max =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Min = ', f'{data_normalized.min(axis=0).round(2)}')\n",
    "print('Max = ', f'{data_normalized.max(axis=0).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. Robust Scaling\\nTransforms data to have a median of 0 and a standard deviation of 1.\\nFormula: X_scaled = (X - median(X)) / (quantile(X, 0.75) - quantile(X, 0.25))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\"\"\"\n",
    "3. Robust Scaling\n",
    "Transforms data to have a median of 0 and a standard deviation of 1.\n",
    "Formula: X_scaled = (X - median(X)) / (quantile(X, 0.75) - quantile(X, 0.25))\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median=  [ 1.    2.55 -1.6   4.25]\n",
      "IQR =  [1.5   2.375 1.875 0.325]\n"
     ]
    }
   ],
   "source": [
    "print('Median= ', np.median(input_data, axis=0))\n",
    "print('IQR = ', np.percentile(input_data, 75, axis=0) - np.percentile(input_data, 25, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.33333333  -1.70526316   2.45333333 -32.76923077]\n",
      " [ -0.66666667   0.18947368   0.16        -0.46153846]\n",
      " [  0.          -0.10526316  -0.69333333   0.15384615]\n",
      " [  0.66666667   0.10526316  -0.37333333   0.76923077]\n",
      " [ -1.33333333   0.31578947  -0.16        -0.15384615]\n",
      " [  0.          -1.07368421   0.85333333   2.30769231]]\n"
     ]
    }
   ],
   "source": [
    "data_robust_scaled = preprocessing.robust_scale(input_data)\n",
    "print(data_robust_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median =  [0. 0. 0. 0.]\n",
      "IQR =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('Median = ', np.median(data_robust_scaled, axis=0).round(2))\n",
    "print('IQR = ', np.percentile(data_robust_scaled, 75, axis=0) - np.percentile(data_robust_scaled, 25, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n4. Normalization\\nTransforms data to have a unit L1 norm (sum of absolute values equals 1).\\n\\nnorm='l1': given a matrix with samples as rows, L1 normalization ensures that each row (sample) has a unit L1 norm (sum of absolute values equals 1)\\nnorm='l2': given a matrix with samples as rows, L2 normalization ensures that each row (sample) has a unit L2 norm (sum of squared values equals 1)\\nnorm='max': given a matrix with samples as rows, max normalization ensures that each row (sample) has a unit max norm (maximum absolute value equals 1)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "\"\"\"\n",
    "4. Normalization\n",
    "Transforms data to have a unit L1 norm (sum of absolute values equals 1).\n",
    "\n",
    "norm='l1': given a matrix with samples as rows, L1 normalization ensures that each row (sample) has a unit L1 norm (sum of absolute values equals 1)\n",
    "norm='l2': given a matrix with samples as rows, L2 normalization ensures that each row (sample) has a unit L2 norm (sum of squared values equals 1)\n",
    "norm='max': given a matrix with samples as rows, max normalization ensures that each row (sample) has a unit max norm (maximum absolute value equals 1)\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21582734 -0.10791367  0.21582734 -0.46043165]\n",
      " [ 0.          0.35714286 -0.1547619   0.48809524]\n",
      " [ 0.0952381   0.21904762 -0.27619048  0.40952381]\n",
      " [ 0.17241379  0.24137931 -0.19827586  0.38793103]\n",
      " [-0.09615385  0.31730769 -0.18269231  0.40384615]\n",
      " [ 0.16666667  0.          0.          0.83333333]]\n"
     ]
    }
   ],
   "source": [
    "# The choice of axis depends on whether you want to normalize each feature across all samples (axis=0 \"in 2D array\") or each sample across all features (axis=1).\n",
    "data_mean_normalization = preprocessing.normalize(input_data, norm='l1', axis=1) \n",
    "# Since data_mean_normalization suggests normalizing data on a per-sample basis, \n",
    "# using axis=1 is generally more common for machine learning tasks where each sample vector is normalized.\n",
    "print(data_mean_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\"\"\"\n",
    "5. Binarization\n",
    "Transforms data into a binary format (0 or 1) based on a threshold value.\n",
    "\"\"\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [1. 1. 0. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "data_binarization = preprocessing.binarize(input_data, threshold=0.5)\n",
    "print(data_binarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
